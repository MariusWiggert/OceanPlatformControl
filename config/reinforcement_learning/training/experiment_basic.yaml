algorithm_name: 'apex-dqn'

# https://docs.ray.io/en/releases-1.13.0/rllib/rllib-algorithms.html#apex
# https://docs.ray.io/en/releases-1.13.0/rllib/rllib-algorithms.html#dqn
# https://docs.ray.io/en/releases-1.13.0/rllib/rllib-training.html#common-parameters
# https://docs.ray.io/en/latest/rllib/rllib-models.html#default-model-config-settings
# https://github.com/ray-project/ray/issues/9425
algorithm:
    ##### Environment #####
    env: 'OceanEnv'
    disable_env_checking: True
    seed: 2022
    ##### Framework #####
    framework: 'torch'
    ##### DQN #####
    num_atoms: 1
    n_step: 1
    noisy: False
    dueling: True
    double_q: True
    ##### Model #####
    model:
        # _use_default_native_models: True
        # Filter config: List of [out_channels, kernel, stride] for each filter.
#        dim: 21
#        conv_filters: [
#            [4, [5, 5], 1],
#            [16, [5, 5], 1],
#            [441, [21, 21], 1]
#        ]
#        conv_activation: 'relu'
        custom_model: 'OceanTorchModel'
        custom_model_config:
            map:
                normalize: True

                units: [ 512, 512 ]
                activation: [ 'tanh', 'tanh' ] # Supported values: "tanh", "relu", "swish", "linear".
                initializer_std: [ 1, 1 ]

#                channels: [ 4, 16 ]
#                kernel: [ [5,5], [5,5] ]
#                stride: []
#                padding: []
#                activation: []

            meta:
                input_activation: 'tanh'
                units: []
                activation: [] # Supported values: "tanh", "relu", "swish", "linear".
                initializer_std: []

            joined:
                units: [ 256, 256 ]
                activation: [ 'tanh', 'relu' ] # Supported values: "tanh", "relu", "swish", "linear".
                initializer_std: [ 0.01, False ]

            dueling_heads:
                units: [ 128, 128 ]
                activation: [ 'relu', 'relu', 'linear' ] # Supported values: "tanh", "relu", "swish", "linear".
                initializer_std: [ False, False, False ] # Supported values: False (), or float (std of normc_initializer)

    _disable_preprocessor_api: True
    ##### Episodes #####
#    batch_mode: 'truncate_episodes'
#    soft_horizon: False
#    rollout_fragment_length: 50
    ##### Training #####
#    replay_buffer_config:
#        capacity: 2000000
#        learning_starts: 10000
#        no_local_replay_buffer: True
#        prioritized_replay_alpha: 0.6
#        prioritized_replay_beta: 0.4
#        prioritized_replay_eps: 0.000001
#        replay_batch_size: 32
#        replay_sequence_length: 1
#        type: 'MultiAgentReplayBuffer'
#    train_batch_size: 512
#    timesteps_per_iteration: 10000
#    training_intensity: 1
#    target_network_update_freq: 10.0e3,
    keep_per_episode_custom_metrics: True
    optimizer:
        num_replay_buffer_shards: 1
    log_level: 'ERROR'
    ##### Exploration #####
#    exploration_config: {"type": "SoftQ"}
        # worker_side_prioritization: True,
    ##### Evaluation #####
#    evaluation_config:
#        evaluation_interval: 1
#        evaluation_duration: 1000
#        evaluation_duration_unit: "episodes"
#        env_config:
#            evaluation: True
    ##### Workers #####
    num_gpus: 1
    num_workers: 102
    num_cpus_per_worker: 1
    num_gpus_per_worker: 0
    placement_strategy: 'SPREAD'
    ignore_worker_failures: True
    recreate_failed_workers: True

experiments_folder: '/seaweed-storage/experiments/gulf_of_mexico_Copernicus_forecast_HYCOM_hindcast/'

environment:
    scenario_name: 'gulf_of_mexico_Copernicus_forecast_HYCOM_hindcast'
    scenario_config: {}

    problem_folder: '/seaweed-storage/generation/gulf_of_mexico_Copernicus_forecast_HYCOM_hindcast/training_40000_problems/'
    validation_length: 2000

    arena_steps_per_env_step: 1
    actions: 8
    render: False
    fake: False #one of: False, 'random', 'naive, 'hj_planner_forecast', 'hj_planner_hindcast', 'residual'

feature_constructor:
    flatten: False
    measurements: False
    local_map:
        xy_width_degree: 0.2
        xy_width_points: 5
        flatten: False
        features:
            ttr_forecast: True
            ttr_hindcast: False
            observer:
                variables: ['error_u', 'error_v'] #['error_u', 'error_v'] #['water_u', 'water_v'], # list from: 'error_u', 'error_v', 'std_error_u', 'std_error_v', 'initial_forecast_u', 'initial_forecast_v', 'water_u', 'water_v'
                time: [0] # offsets in h
            currents_hindcast: [] # offsets in h
            currents_forecast: [] # offsets in h
            true_error: [] # offsets in h
    global_map: False
    meta: False #['lon', 'lat'] #, 'time', 'target_distance', 'target_direction', 'episode_time_in_h']

reward_function:
    delta_ttr_forecast: 0
    delta_ttr_hindcast: 1
    step_punishment: 0 # 0.16
    target_bonus: 0
    fail_punishment: 0