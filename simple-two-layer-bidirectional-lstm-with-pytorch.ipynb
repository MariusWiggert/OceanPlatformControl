{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Simple two-layer bidirectional LSTM with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 250\n",
    "lr = 0.01\n",
    "n_folds = 5\n",
    "lstm_input_size = 1\n",
    "hidden_state_size = 30\n",
    "batch_size = 30\n",
    "num_sequence_layers = 2\n",
    "output_dim = 11\n",
    "num_time_steps = 4000\n",
    "rnn_type = 'LSTM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Bi_RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=11, num_layers=2, rnn_type='LSTM'):\n",
    "        super(Bi_RNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        #Define the initial linear hidden layer\n",
    "        self.init_linear = nn.Linear(self.input_dim, self.input_dim)\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = eval('nn.' + rnn_type)(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, bidirectional=True)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim * 2, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        #Forward pass through initial hidden layer\n",
    "        linear_input = self.init_linear(input)\n",
    "\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [batch_size, input_size ,hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both\n",
    "        # have shape (batch_size, num_layers, hidden_dim).\n",
    "        lstm_out, self.hidden = self.lstm(linear_input)\n",
    "\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        y_pred = self.linear(lstm_out)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ION_Dataset_Sequential(Dataset):\n",
    "    def __init__(self, input, output):\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.input[idx]\n",
    "        y = self.output[idx]\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        y = torch.tensor(y, dtype=torch.float)\n",
    "        return x, y\n",
    "\n",
    "class ION_Dataset_Sequential_test(Dataset):\n",
    "    def __init__(self, input):\n",
    "        self.input = input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.input[idx]\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import data\n",
    "\n",
    "We removed the drift following https://www.kaggle.com/cdeotte/one-feature-model-0-930/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/data-no-drift/train_detrend.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m train_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/kaggle/input/data-no-drift/train_detrend.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m test_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/kaggle/input/data-no-drift/test_detrend.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m X \u001B[38;5;241m=\u001B[39m train_df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msignal\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, num_time_steps, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ocean_platform/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ocean_platform/lib/python3.9/site-packages/pandas/io/parsers/readers.py:586\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    571\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    572\u001B[0m     dialect,\n\u001B[1;32m    573\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    582\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    583\u001B[0m )\n\u001B[1;32m    584\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 586\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ocean_platform/lib/python3.9/site-packages/pandas/io/parsers/readers.py:482\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    479\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    481\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 482\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    485\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ocean_platform/lib/python3.9/site-packages/pandas/io/parsers/readers.py:811\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m kwds:\n\u001B[1;32m    809\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 811\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ocean_platform/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1040\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1036\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1037\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown engine: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mengine\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (valid options are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmapping\u001B[38;5;241m.\u001B[39mkeys()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1038\u001B[0m     )\n\u001B[1;32m   1039\u001B[0m \u001B[38;5;66;03m# error: Too many arguments for \"ParserBase\"\u001B[39;00m\n\u001B[0;32m-> 1040\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmapping\u001B[49m\u001B[43m[\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ocean_platform/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:51\u001B[0m, in \u001B[0;36mCParserWrapper.__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m     48\u001B[0m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124musecols\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39musecols\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# open handles\u001B[39;00m\n\u001B[0;32m---> 51\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open_handles\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;66;03m# Have to pass int, would break tests using TextReader directly otherwise :(\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ocean_platform/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py:222\u001B[0m, in \u001B[0;36mParserBase._open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_handles\u001B[39m(\u001B[38;5;28mself\u001B[39m, src: FilePathOrBuffer, kwds: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;124;03m    Let the readers open IOHandles after they are done with their potential raises.\u001B[39;00m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 222\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    228\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    229\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ocean_platform/lib/python3.9/site-packages/pandas/io/common.py:702\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    697\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    698\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    701\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 702\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    709\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    710\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    711\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/kaggle/input/data-no-drift/train_detrend.csv'"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/data-no-drift/train_detrend.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/data-no-drift/test_detrend.csv')\n",
    "X = train_df['signal'].values.reshape(-1, num_time_steps, 1)\n",
    "y = pd.get_dummies(train_df['open_channels']).values.reshape(-1, num_time_steps, output_dim)\n",
    "test_input = test_df[\"signal\"].values.reshape(-1, num_time_steps, 1)\n",
    "train_input_mean = X.mean()\n",
    "train_input_sigma = X.std()\n",
    "test_input = (test_input-train_input_mean)/train_input_sigma\n",
    "test_preds = np.zeros((int(test_input.shape[0] * test_input.shape[1])))\n",
    "test = ION_Dataset_Sequential_test(test_input)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train, evaluate with 5-fold CV and keep best model on every fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fold 0\n",
      "###### splitting and reshaping the data\n",
      "(1000, 4000, 1)\n",
      "###### Loading\n",
      "Epoch 1/250 \t loss=0.3245 \t train_f1=0.0533 \t val_loss=0.2822 \t val_f1=0.0366 \t time=20.61s\n",
      "Epoch 11/250 \t loss=0.0325 \t train_f1=0.8263 \t val_loss=0.0360 \t val_f1=0.8259 \t time=19.30s\n",
      "Epoch 21/250 \t loss=0.0222 \t train_f1=0.9200 \t val_loss=0.0272 \t val_f1=0.9126 \t time=19.29s\n",
      "Epoch 31/250 \t loss=0.0210 \t train_f1=0.9221 \t val_loss=0.0275 \t val_f1=0.9094 \t time=19.24s\n",
      "Epoch 41/250 \t loss=0.0200 \t train_f1=0.9250 \t val_loss=0.0229 \t val_f1=0.9233 \t time=20.48s\n",
      "Epoch 51/250 \t loss=0.0197 \t train_f1=0.9241 \t val_loss=0.0227 \t val_f1=0.9240 \t time=19.00s\n",
      "Epoch 61/250 \t loss=0.0197 \t train_f1=0.9235 \t val_loss=0.0229 \t val_f1=0.9220 \t time=19.14s\n",
      "Epoch 71/250 \t loss=0.0197 \t train_f1=0.9243 \t val_loss=0.0226 \t val_f1=0.9229 \t time=19.07s\n",
      "Epoch 81/250 \t loss=0.0195 \t train_f1=0.9242 \t val_loss=0.0239 \t val_f1=0.9144 \t time=20.03s\n",
      "Epoch 91/250 \t loss=0.0225 \t train_f1=0.9192 \t val_loss=0.0249 \t val_f1=0.9194 \t time=19.57s\n",
      "Epoch 101/250 \t loss=0.0190 \t train_f1=0.9230 \t val_loss=0.0213 \t val_f1=0.9265 \t time=19.52s\n",
      "Epoch 111/250 \t loss=0.0179 \t train_f1=0.9264 \t val_loss=0.0212 \t val_f1=0.9261 \t time=19.01s\n",
      "Epoch 121/250 \t loss=0.0191 \t train_f1=0.9250 \t val_loss=0.0233 \t val_f1=0.9221 \t time=19.89s\n",
      "Epoch 131/250 \t loss=0.0186 \t train_f1=0.9256 \t val_loss=0.0220 \t val_f1=0.9244 \t time=19.58s\n",
      "Epoch 141/250 \t loss=0.0179 \t train_f1=0.9273 \t val_loss=0.0218 \t val_f1=0.9202 \t time=19.50s\n",
      "Epoch 151/250 \t loss=0.0404 \t train_f1=0.8610 \t val_loss=0.0362 \t val_f1=0.9026 \t time=19.21s\n",
      "Epoch 161/250 \t loss=0.0206 \t train_f1=0.9212 \t val_loss=0.0238 \t val_f1=0.9158 \t time=19.73s\n",
      "Epoch 171/250 \t loss=0.0188 \t train_f1=0.9252 \t val_loss=0.0223 \t val_f1=0.9218 \t time=19.45s\n",
      "Epoch 181/250 \t loss=0.0190 \t train_f1=0.9251 \t val_loss=0.0224 \t val_f1=0.9184 \t time=19.20s\n",
      "Epoch 191/250 \t loss=0.0187 \t train_f1=0.9229 \t val_loss=0.0213 \t val_f1=0.9249 \t time=19.29s\n",
      "Epoch 201/250 \t loss=0.0183 \t train_f1=0.9263 \t val_loss=0.0216 \t val_f1=0.9256 \t time=20.06s\n",
      "Epoch 211/250 \t loss=0.0181 \t train_f1=0.9274 \t val_loss=0.0217 \t val_f1=0.9247 \t time=20.00s\n",
      "Epoch 221/250 \t loss=0.0186 \t train_f1=0.9258 \t val_loss=0.0213 \t val_f1=0.9266 \t time=19.47s\n",
      "Epoch 231/250 \t loss=0.0186 \t train_f1=0.9255 \t val_loss=0.0217 \t val_f1=0.9252 \t time=19.37s\n",
      "Epoch 241/250 \t loss=0.0174 \t train_f1=0.9286 \t val_loss=0.0217 \t val_f1=0.9260 \t time=20.11s\n",
      "BEST VALIDATION SCORE (F1):  0.9275561937147053\n",
      "starting fold 1\n",
      "###### splitting and reshaping the data\n",
      "(1000, 4000, 1)\n",
      "###### Loading\n",
      "Epoch 1/250 \t loss=0.3191 \t train_f1=0.0606 \t val_loss=0.2860 \t val_f1=0.0323 \t time=19.19s\n",
      "Epoch 11/250 \t loss=0.1350 \t train_f1=0.6671 \t val_loss=0.1140 \t val_f1=0.6634 \t time=19.37s\n",
      "Epoch 21/250 \t loss=0.0330 \t train_f1=0.9024 \t val_loss=0.0391 \t val_f1=0.9036 \t time=20.25s\n",
      "Epoch 31/250 \t loss=0.0249 \t train_f1=0.9153 \t val_loss=0.0315 \t val_f1=0.9118 \t time=20.33s\n",
      "Epoch 41/250 \t loss=0.0228 \t train_f1=0.9181 \t val_loss=0.0291 \t val_f1=0.9176 \t time=19.26s\n",
      "Epoch 51/250 \t loss=0.0228 \t train_f1=0.9194 \t val_loss=0.0284 \t val_f1=0.9185 \t time=19.00s\n",
      "Epoch 61/250 \t loss=0.0211 \t train_f1=0.9219 \t val_loss=0.0287 \t val_f1=0.9168 \t time=19.85s\n",
      "Epoch 71/250 \t loss=0.0207 \t train_f1=0.9212 \t val_loss=0.0267 \t val_f1=0.9211 \t time=19.43s\n",
      "Epoch 81/250 \t loss=0.0207 \t train_f1=0.9228 \t val_loss=0.0258 \t val_f1=0.9185 \t time=19.20s\n",
      "Epoch 91/250 \t loss=0.0206 \t train_f1=0.9224 \t val_loss=0.0319 \t val_f1=0.9126 \t time=18.90s\n",
      "Epoch 101/250 \t loss=0.0201 \t train_f1=0.9234 \t val_loss=0.0259 \t val_f1=0.9215 \t time=18.93s\n",
      "Epoch 111/250 \t loss=0.0216 \t train_f1=0.9186 \t val_loss=0.0273 \t val_f1=0.9190 \t time=19.79s\n",
      "Epoch 121/250 \t loss=0.0284 \t train_f1=0.9057 \t val_loss=0.0325 \t val_f1=0.9115 \t time=19.19s\n",
      "Epoch 131/250 \t loss=0.0210 \t train_f1=0.9214 \t val_loss=0.0281 \t val_f1=0.9189 \t time=18.99s\n",
      "Epoch 141/250 \t loss=0.0211 \t train_f1=0.9190 \t val_loss=0.0269 \t val_f1=0.9184 \t time=19.32s\n",
      "Epoch 151/250 \t loss=0.0204 \t train_f1=0.9224 \t val_loss=0.0262 \t val_f1=0.9209 \t time=19.70s\n",
      "Epoch 161/250 \t loss=0.0203 \t train_f1=0.9224 \t val_loss=0.0257 \t val_f1=0.9219 \t time=19.67s\n",
      "Epoch 171/250 \t loss=0.0203 \t train_f1=0.9221 \t val_loss=0.0268 \t val_f1=0.9179 \t time=18.92s\n",
      "Epoch 181/250 \t loss=0.0199 \t train_f1=0.9236 \t val_loss=0.0253 \t val_f1=0.9178 \t time=19.04s\n",
      "Epoch 191/250 \t loss=0.0203 \t train_f1=0.9233 \t val_loss=0.0253 \t val_f1=0.9216 \t time=19.10s\n",
      "Epoch 201/250 \t loss=0.0200 \t train_f1=0.9236 \t val_loss=0.0255 \t val_f1=0.9223 \t time=19.52s\n",
      "Epoch 211/250 \t loss=0.0200 \t train_f1=0.9236 \t val_loss=0.0257 \t val_f1=0.9227 \t time=19.42s\n",
      "Epoch 221/250 \t loss=0.0206 \t train_f1=0.9214 \t val_loss=0.0263 \t val_f1=0.9168 \t time=18.98s\n",
      "Epoch 231/250 \t loss=0.0204 \t train_f1=0.9229 \t val_loss=0.0248 \t val_f1=0.9213 \t time=19.01s\n",
      "Epoch 241/250 \t loss=0.0194 \t train_f1=0.9242 \t val_loss=0.0251 \t val_f1=0.9191 \t time=18.84s\n",
      "BEST VALIDATION SCORE (F1):  0.9235153624787974\n",
      "starting fold 2\n",
      "###### splitting and reshaping the data\n",
      "(1000, 4000, 1)\n",
      "###### Loading\n",
      "Epoch 1/250 \t loss=0.3244 \t train_f1=0.0576 \t val_loss=0.2819 \t val_f1=0.0301 \t time=19.42s\n",
      "Epoch 11/250 \t loss=0.0370 \t train_f1=0.8230 \t val_loss=0.0379 \t val_f1=0.8238 \t time=19.43s\n",
      "Epoch 21/250 \t loss=0.0231 \t train_f1=0.8814 \t val_loss=0.0249 \t val_f1=0.9133 \t time=19.04s\n",
      "Epoch 31/250 \t loss=0.0213 \t train_f1=0.9180 \t val_loss=0.0227 \t val_f1=0.9248 \t time=19.09s\n",
      "Epoch 41/250 \t loss=0.0205 \t train_f1=0.9218 \t val_loss=0.0226 \t val_f1=0.9265 \t time=19.00s\n",
      "Epoch 51/250 \t loss=0.0210 \t train_f1=0.9182 \t val_loss=0.0213 \t val_f1=0.9274 \t time=19.52s\n",
      "Epoch 61/250 \t loss=0.0202 \t train_f1=0.9186 \t val_loss=0.0214 \t val_f1=0.9262 \t time=19.79s\n",
      "Epoch 71/250 \t loss=0.0201 \t train_f1=0.9229 \t val_loss=0.0221 \t val_f1=0.9224 \t time=19.00s\n",
      "Epoch 81/250 \t loss=0.0198 \t train_f1=0.9232 \t val_loss=0.0230 \t val_f1=0.9217 \t time=18.83s\n",
      "Epoch 91/250 \t loss=0.0193 \t train_f1=0.9241 \t val_loss=0.0224 \t val_f1=0.9229 \t time=19.10s\n",
      "Epoch 101/250 \t loss=0.0202 \t train_f1=0.9203 \t val_loss=0.0248 \t val_f1=0.9216 \t time=20.10s\n",
      "Epoch 111/250 \t loss=0.0190 \t train_f1=0.9245 \t val_loss=0.0210 \t val_f1=0.9281 \t time=19.09s\n",
      "Epoch 121/250 \t loss=0.0191 \t train_f1=0.9238 \t val_loss=0.0216 \t val_f1=0.9267 \t time=18.82s\n",
      "Epoch 131/250 \t loss=0.0185 \t train_f1=0.9260 \t val_loss=0.0210 \t val_f1=0.9280 \t time=18.96s\n",
      "Epoch 141/250 \t loss=0.0185 \t train_f1=0.9257 \t val_loss=0.0206 \t val_f1=0.9273 \t time=18.94s\n",
      "Epoch 151/250 \t loss=0.0191 \t train_f1=0.9239 \t val_loss=0.0219 \t val_f1=0.9235 \t time=19.60s\n",
      "Epoch 161/250 \t loss=0.0189 \t train_f1=0.9251 \t val_loss=0.0204 \t val_f1=0.9285 \t time=19.65s\n",
      "Epoch 171/250 \t loss=0.0180 \t train_f1=0.9266 \t val_loss=0.0225 \t val_f1=0.9211 \t time=18.95s\n",
      "Epoch 181/250 \t loss=0.0186 \t train_f1=0.9258 \t val_loss=0.0212 \t val_f1=0.9272 \t time=18.89s\n",
      "Epoch 191/250 \t loss=0.0189 \t train_f1=0.9257 \t val_loss=0.0204 \t val_f1=0.9293 \t time=19.64s\n",
      "Epoch 201/250 \t loss=0.0185 \t train_f1=0.9242 \t val_loss=0.0213 \t val_f1=0.9283 \t time=19.83s\n",
      "Epoch 211/250 \t loss=0.0202 \t train_f1=0.9225 \t val_loss=0.0212 \t val_f1=0.9271 \t time=18.95s\n",
      "Epoch 221/250 \t loss=0.0180 \t train_f1=0.9243 \t val_loss=0.0204 \t val_f1=0.9255 \t time=18.91s\n",
      "Epoch 231/250 \t loss=0.0179 \t train_f1=0.9263 \t val_loss=0.0209 \t val_f1=0.9270 \t time=19.15s\n",
      "Epoch 241/250 \t loss=0.0176 \t train_f1=0.9276 \t val_loss=0.0197 \t val_f1=0.9294 \t time=19.42s\n",
      "BEST VALIDATION SCORE (F1):  0.9303433252095854\n",
      "starting fold 3\n",
      "###### splitting and reshaping the data\n",
      "(1000, 4000, 1)\n",
      "###### Loading\n",
      "Epoch 1/250 \t loss=0.3282 \t train_f1=0.0542 \t val_loss=0.2766 \t val_f1=0.0393 \t time=19.25s\n",
      "Epoch 11/250 \t loss=0.0519 \t train_f1=0.7038 \t val_loss=0.0518 \t val_f1=0.7109 \t time=19.14s\n",
      "Epoch 21/250 \t loss=0.0270 \t train_f1=0.8475 \t val_loss=0.0274 \t val_f1=0.9026 \t time=19.67s\n",
      "Epoch 31/250 \t loss=0.0239 \t train_f1=0.9150 \t val_loss=0.0234 \t val_f1=0.9197 \t time=19.52s\n",
      "Epoch 41/250 \t loss=0.0217 \t train_f1=0.9204 \t val_loss=0.0220 \t val_f1=0.9249 \t time=19.90s\n",
      "Epoch 51/250 \t loss=0.0212 \t train_f1=0.9208 \t val_loss=0.0220 \t val_f1=0.9251 \t time=19.15s\n",
      "Epoch 61/250 \t loss=0.0215 \t train_f1=0.9203 \t val_loss=0.0221 \t val_f1=0.9253 \t time=19.15s\n",
      "Epoch 71/250 \t loss=0.0206 \t train_f1=0.9215 \t val_loss=0.0220 \t val_f1=0.9241 \t time=18.88s\n",
      "Epoch 81/250 \t loss=0.0206 \t train_f1=0.9207 \t val_loss=0.0220 \t val_f1=0.9245 \t time=19.53s\n",
      "Epoch 91/250 \t loss=0.0205 \t train_f1=0.9229 \t val_loss=0.0217 \t val_f1=0.9175 \t time=19.89s\n",
      "Epoch 101/250 \t loss=0.0201 \t train_f1=0.9218 \t val_loss=0.0209 \t val_f1=0.9249 \t time=19.06s\n",
      "Epoch 111/250 \t loss=0.0209 \t train_f1=0.9216 \t val_loss=0.0225 \t val_f1=0.9029 \t time=19.00s\n",
      "Epoch 121/250 \t loss=0.0202 \t train_f1=0.9204 \t val_loss=0.0202 \t val_f1=0.9262 \t time=19.30s\n",
      "Epoch 131/250 \t loss=0.0192 \t train_f1=0.9252 \t val_loss=0.0197 \t val_f1=0.9278 \t time=19.84s\n",
      "Epoch 141/250 \t loss=0.0196 \t train_f1=0.9240 \t val_loss=0.0203 \t val_f1=0.9251 \t time=19.19s\n",
      "Epoch 151/250 \t loss=0.0196 \t train_f1=0.9230 \t val_loss=0.0205 \t val_f1=0.9227 \t time=19.03s\n",
      "Epoch 161/250 \t loss=0.0186 \t train_f1=0.9261 \t val_loss=0.0193 \t val_f1=0.9296 \t time=18.91s\n",
      "Epoch 171/250 \t loss=0.0182 \t train_f1=0.9262 \t val_loss=0.0190 \t val_f1=0.9295 \t time=18.84s\n",
      "Epoch 181/250 \t loss=0.0187 \t train_f1=0.9254 \t val_loss=0.0197 \t val_f1=0.9234 \t time=19.70s\n",
      "Epoch 191/250 \t loss=0.0182 \t train_f1=0.9269 \t val_loss=0.0192 \t val_f1=0.9272 \t time=19.37s\n",
      "Epoch 201/250 \t loss=0.0182 \t train_f1=0.9248 \t val_loss=0.0190 \t val_f1=0.9294 \t time=19.04s\n",
      "Epoch 211/250 \t loss=0.0206 \t train_f1=0.9204 \t val_loss=0.0203 \t val_f1=0.9279 \t time=19.07s\n",
      "Epoch 221/250 \t loss=0.0186 \t train_f1=0.9240 \t val_loss=0.0191 \t val_f1=0.9294 \t time=19.28s\n",
      "Epoch 231/250 \t loss=0.0182 \t train_f1=0.9256 \t val_loss=0.0210 \t val_f1=0.9264 \t time=20.82s\n",
      "Epoch 241/250 \t loss=0.0185 \t train_f1=0.9248 \t val_loss=0.0193 \t val_f1=0.9293 \t time=19.20s\n",
      "BEST VALIDATION SCORE (F1):  0.931120720805544\n",
      "starting fold 4\n",
      "###### splitting and reshaping the data\n",
      "(1000, 4000, 1)\n",
      "###### Loading\n",
      "Epoch 1/250 \t loss=0.3178 \t train_f1=0.0709 \t val_loss=0.2782 \t val_f1=0.0335 \t time=19.23s\n",
      "Epoch 11/250 \t loss=0.0348 \t train_f1=0.8209 \t val_loss=0.0406 \t val_f1=0.8255 \t time=20.01s\n",
      "Epoch 21/250 \t loss=0.0234 \t train_f1=0.9107 \t val_loss=0.0284 \t val_f1=0.9162 \t time=19.49s\n",
      "Epoch 31/250 \t loss=0.0211 \t train_f1=0.9197 \t val_loss=0.0261 \t val_f1=0.9211 \t time=19.01s\n",
      "Epoch 41/250 \t loss=0.0199 \t train_f1=0.9229 \t val_loss=0.0263 \t val_f1=0.9202 \t time=19.08s\n",
      "Epoch 51/250 \t loss=0.0203 \t train_f1=0.9178 \t val_loss=0.0267 \t val_f1=0.9082 \t time=19.28s\n",
      "Epoch 61/250 \t loss=0.0207 \t train_f1=0.9186 \t val_loss=0.0288 \t val_f1=0.9097 \t time=19.49s\n",
      "Epoch 71/250 \t loss=0.0197 \t train_f1=0.9215 \t val_loss=0.0262 \t val_f1=0.9127 \t time=19.13s\n",
      "Epoch 81/250 \t loss=0.0345 \t train_f1=0.8805 \t val_loss=0.0366 \t val_f1=0.9002 \t time=18.95s\n",
      "Epoch 91/250 \t loss=0.0204 \t train_f1=0.9232 \t val_loss=0.0261 \t val_f1=0.9208 \t time=19.10s\n",
      "Epoch 101/250 \t loss=0.0194 \t train_f1=0.9228 \t val_loss=0.0247 \t val_f1=0.9235 \t time=19.64s\n",
      "Epoch 111/250 \t loss=0.0196 \t train_f1=0.9207 \t val_loss=0.0249 \t val_f1=0.9218 \t time=19.81s\n",
      "Epoch 121/250 \t loss=0.0208 \t train_f1=0.9195 \t val_loss=0.0289 \t val_f1=0.9059 \t time=19.30s\n",
      "Epoch 131/250 \t loss=0.0190 \t train_f1=0.9241 \t val_loss=0.0241 \t val_f1=0.9235 \t time=19.30s\n",
      "Epoch 141/250 \t loss=0.0188 \t train_f1=0.9247 \t val_loss=0.0244 \t val_f1=0.9231 \t time=19.79s\n",
      "Epoch 151/250 \t loss=0.0197 \t train_f1=0.9216 \t val_loss=0.0257 \t val_f1=0.9203 \t time=19.78s\n",
      "Epoch 161/250 \t loss=0.0195 \t train_f1=0.9230 \t val_loss=0.0250 \t val_f1=0.9172 \t time=19.32s\n",
      "Epoch 171/250 \t loss=0.0184 \t train_f1=0.9257 \t val_loss=0.0245 \t val_f1=0.9236 \t time=19.58s\n",
      "Epoch 181/250 \t loss=0.0188 \t train_f1=0.9236 \t val_loss=0.0249 \t val_f1=0.9199 \t time=20.44s\n",
      "Epoch 191/250 \t loss=0.0190 \t train_f1=0.9204 \t val_loss=0.0246 \t val_f1=0.9204 \t time=19.39s\n",
      "Epoch 201/250 \t loss=0.0188 \t train_f1=0.9252 \t val_loss=0.0244 \t val_f1=0.9234 \t time=19.39s\n",
      "Epoch 211/250 \t loss=0.0182 \t train_f1=0.9258 \t val_loss=0.0238 \t val_f1=0.9238 \t time=20.55s\n",
      "Epoch 221/250 \t loss=0.0188 \t train_f1=0.9250 \t val_loss=0.0267 \t val_f1=0.9160 \t time=19.76s\n",
      "Epoch 231/250 \t loss=0.0182 \t train_f1=0.9255 \t val_loss=0.0241 \t val_f1=0.9217 \t time=19.65s\n",
      "Epoch 241/250 \t loss=0.0196 \t train_f1=0.9203 \t val_loss=0.0252 \t val_f1=0.9228 \t time=19.98s\n",
      "BEST VALIDATION SCORE (F1):  0.9258702590756225\n",
      "Final Score  0.9276811722568509\n"
     ]
    }
   ],
   "source": [
    "#Iterate through folds\n",
    "\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "local_val_score = 0\n",
    "models = {}\n",
    "\n",
    "k=0 #initialize fold number\n",
    "for tr_idx, val_idx in kfold.split(X, y):\n",
    "    test_p = np.zeros((int(test_input.shape[0] * test_input.shape[1])))\n",
    "\n",
    "    print('starting fold', k)\n",
    "    k += 1\n",
    "\n",
    "    print(6*'#', 'splitting and reshaping the data')\n",
    "    train_input = X[tr_idx]\n",
    "    print(train_input.shape)\n",
    "    train_target = y[tr_idx]\n",
    "    val_input = X[val_idx]\n",
    "    val_target = y[val_idx]\n",
    "    train_input_mean = train_input.mean()\n",
    "    train_input_sigma = train_input.std()\n",
    "    val_input = (val_input-train_input_mean)/train_input_sigma\n",
    "    train_input = (train_input-train_input_mean)/train_input_sigma\n",
    "\n",
    "    print(6*'#', 'Loading')\n",
    "    train = ION_Dataset_Sequential(train_input, train_target)\n",
    "    valid = ION_Dataset_Sequential(val_input, val_target)\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    #Build tensor data for torch\n",
    "    train_preds = np.zeros((int(train_input.shape[0] * train_input.shape[1])))\n",
    "    val_preds = np.zeros((int(val_input.shape[0] * val_input.shape[1])))\n",
    "    best_val_preds = np.zeros((int(val_input.shape[0] * val_input.shape[1])))\n",
    "    train_targets = np.zeros((int(train_input.shape[0] * train_input.shape[1])))\n",
    "    avg_losses_f = []\n",
    "    avg_val_losses_f = []\n",
    "\n",
    "    #Define loss function\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    #Build model, initialize weights and define optimizer\n",
    "    model = Bi_RNN(lstm_input_size, hidden_state_size, batch_size=batch_size, output_dim=output_dim, num_layers=num_sequence_layers, rnn_type=rnn_type)  # (input_dim, hidden_state_size, batch_size, output_dim, num_seq_layers, rnn_type)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)  # Using Adam optimizer\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=150, factor=0.1, min_lr=1e-8)  # Using ReduceLROnPlateau schedule\n",
    "    temp_val_loss = 9999999999\n",
    "    reached_val_score = 0\n",
    "\n",
    "    #Iterate through epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        #Train\n",
    "        model.train()\n",
    "        avg_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            x_batch = x_batch.view(-1, num_time_steps, lstm_input_size)\n",
    "            y_batch = y_batch.view(-1, num_time_steps, output_dim)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x_batch.cuda())\n",
    "            loss = loss_fn(y_pred.cpu(), y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss.item() / len(train_loader)\n",
    "            pred = F.softmax(y_pred, 2).detach().cpu().numpy().argmax(axis=-1)\n",
    "            train_preds[i * batch_size * train_input.shape[1]:(i + 1) * batch_size * train_input.shape[1]] = pred.reshape((-1))\n",
    "            train_targets[i * batch_size * train_input.shape[1]:(i + 1) * batch_size * train_input.shape[1]] = y_batch.detach().cpu().numpy().argmax(axis=2).reshape((-1))\n",
    "            del y_pred, loss, x_batch, y_batch, pred\n",
    "\n",
    "        #Evaluate\n",
    "        model.eval()\n",
    "        avg_val_loss = 0.\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "            x_batch = x_batch.view(-1, num_time_steps, lstm_input_size)\n",
    "            y_batch = y_batch.view(-1, num_time_steps, output_dim)\n",
    "            y_pred = model(x_batch.cuda()).detach()\n",
    "            avg_val_loss += loss_fn(y_pred.cpu(), y_batch).item() / len(valid_loader)\n",
    "            pred = F.softmax(y_pred, 2).detach().cpu().numpy().argmax(axis=-1)\n",
    "            val_preds[i * batch_size * val_input.shape[1]:(i + 1) * batch_size * val_input.shape[1]] = pred.reshape((-1))\n",
    "            del y_pred, x_batch, y_batch, pred\n",
    "        if avg_val_loss < temp_val_loss:\n",
    "            temp_val_loss = avg_val_loss\n",
    "\n",
    "        #Calculate F1-score\n",
    "        train_score = f1_score(train_targets, train_preds, average='macro')\n",
    "        val_score = f1_score(val_target.argmax(axis=2).reshape((-1)), val_preds, average='macro')\n",
    "\n",
    "        #Print output of epoch\n",
    "        elapsed_time = time.time() - start_time\n",
    "        scheduler.step(avg_val_loss)\n",
    "        if epoch%10 == 0:\n",
    "            print('Epoch {}/{} \\t loss={:.4f} \\t train_f1={:.4f} \\t val_loss={:.4f} \\t val_f1={:.4f} \\t time={:.2f}s'.format(epoch + 1, n_epochs, avg_loss, train_score, avg_val_loss, val_score, elapsed_time))\n",
    "\n",
    "        if val_score > reached_val_score:\n",
    "            reached_val_score = val_score\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            best_val_preds = copy.deepcopy(val_preds)\n",
    "\n",
    "    #Calculate F1-score of the fold\n",
    "    val_score_fold = f1_score(val_target.argmax(axis=2).reshape((-1)), best_val_preds, average='macro')\n",
    "\n",
    "    #Save the fold's model in a dictionary\n",
    "    models[k] = best_model\n",
    "\n",
    "    #Print F1-score of the fold\n",
    "    print(\"BEST VALIDATION SCORE (F1): \", val_score_fold)\n",
    "    local_val_score += (1/n_folds) * val_score_fold\n",
    "\n",
    "#Print final average k-fold CV F1-score\n",
    "print(\"Final Score \", local_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predict test data by averaging model results from 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Iterate through folds\n",
    "\n",
    "for k in range(n_folds):\n",
    "    test_p = np.zeros((int(test_input.shape[0] * test_input.shape[1])))\n",
    "    k += 1\n",
    "\n",
    "    #Import model of fold k\n",
    "    model = Bi_RNN(lstm_input_size, hidden_state_size, batch_size=batch_size, output_dim=output_dim, num_layers=num_sequence_layers, rnn_type=rnn_type)  # (input_dim, hidden_state_size, batch_size, output_dim, num_seq_layers, rnn_type)\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(models[k])\n",
    "\n",
    "    #Make predictions on test data\n",
    "    model.eval()\n",
    "    for i, x_batch in enumerate(test_loader):\n",
    "        x_batch = x_batch.view(-1, num_time_steps, lstm_input_size)\n",
    "        y_pred = model(x_batch.cuda()).detach()\n",
    "        pred = F.softmax(y_pred, 2).detach().cpu().numpy().argmax(axis=-1)\n",
    "        test_p[i * batch_size * test_input.shape[1]:(i + 1) * batch_size * test_input.shape[1]] = pred.reshape((-1))\n",
    "        del y_pred, x_batch, pred\n",
    "    test_preds += (1/n_folds) * test_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Create submission file\n",
    "df_sub = pd.read_csv(\"/kaggle/input/liverpool-ion-switching/sample_submission.csv\", dtype = {'time': str})\n",
    "df_sub.open_channels = np.array(test_preds, np.int)\n",
    "df_sub.to_csv(\"submission_bilstm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}